{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59440758",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08ac314f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9309b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e360339",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatGroq(model=\"deepseek-r1-distill-llama-70b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "410c7a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I need to figure out the capital of France. Hmm, I think I've heard this before, but I'm not entirely sure. Let me try to remember. I know that France is a country in Europe, and I believe its capital is a pretty famous city. Maybe Paris? That sounds familiar. I've heard of the Eiffel Tower, which is in Paris, right? So, if Paris is the capital, that makes sense because a lot of countries have their capitals associated with well-known landmarks.\n",
      "\n",
      "Wait, but I'm not 100% certain. Could there be another city that's the capital? I don't think so. I remember learning that London is the capital of England, Berlin is the capital of Germany, and Paris for France. Yeah, that seems to line up. I don't think it's Lyon or Marseille because those are other cities in France but not the capital.\n",
      "\n",
      "I guess another way to confirm would be to think about government buildings. The capital usually has the main government offices and the president's residence. I think the French president lives in Paris, so that must be the capital. Also, when I think of French culture, Paris is the center for fashion, art, and cuisine, which are often centered in the capital city.\n",
      "\n",
      "So, putting it all together, Paris is the capital of France. I don't remember any other city being the capital, and all the landmarks and government aspects point to Paris. I think that's the correct answer.\n",
      "</think>\n",
      "\n",
      "The capital of France is Paris. This conclusion is supported by the association of Paris with significant landmarks like the Eiffel Tower, its role as a cultural and governmental center, and the presence of the French president's residence there.\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(\"What is the capital of France?\").content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fd2c84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MILAN\\AppData\\Local\\Temp\\ipykernel_35252\\156554669.py:4: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  search_tool=TavilySearchResults(tavily_api_key=TAVILY_API_KEY)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "TAVILY_API_KEY=os.getenv(\"TAVILY_API_KEY\")\n",
    "search_tool=TavilySearchResults(tavily_api_key=TAVILY_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2df5db67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Facts About France | Map, Population & Capital - Study.com',\n",
       "  'url': 'https://study.com/academy/lesson/facts-about-france-location-population-history.html',\n",
       "  'content': \"France is a large European country. The capital of France is Paris, a well-known city. France is very culturally influential. As an example of that cultural influence, the French language is spoken by millions of people outside of France.\\n\\nThe country's official name is the French Republic; it is a democratic country with a republican form of government. The following is the flag of France:\\n\\nThe flag of France dates back to the French Revolution\\n\\nImage 4: Blue, white, and red tricolor [...] France has one of the highest life expectancies in the world, demonstrating its wealth. It does, however, have an average fertility rate and a below-average birth rate.\\n\\n### Capital of France\\n\\nParis is the capital of France and one of the most well-known cities in the world. It is the home to many world-famous attractions, including: [...] #### What are five interesting facts about France?\\n\\nFrance's capital is Paris. France has a population of 68 million. The language of France (French) is spoken by many more millions of people across the world. France was once ruled by Napoleon Bonaparte. Napoleon successfully waged war against a coalition of other major European powers for many years.\\n\\n### Register to view this lesson\\n\\nAre you a student or a teacher?\\n\\n I am a student  I am a teacher \\n\\n#### Unlock Your Education\",\n",
       "  'score': 0.9055316},\n",
       " {'title': 'Paris facts: the capital of France in history',\n",
       "  'url': 'https://home.adelphi.edu/~ca19535/page%204.html',\n",
       "  'content': 'page 4\\n\\n|  |  |  |  |  |  |  |\\n| --- | --- | --- | --- | --- | --- | --- |\\n| Home | Spain | Sydney | San Francisco | Paris | Las Vegas | Maui |\\n\\n  \\nParis, France  \\n\\n  \\n\\n## Paris facts: Paris, the capital of France\\n\\nParis is the capital of France,\\nthe largest country of Europe\\nwith 550 000 km2 (65 millions inhabitants).\\n\\nParis has 2.234 million inhabitants\\nend 2011. She is the core of Ile de France region (12 million\\npeople). [...] Paris remained the capital of\\nFrance until today, with one four year interruption. During\\nGerman occupation (WW2 , 1940-1944), the capital of France was Vichy.\\n\\ngo to top\\n\\nReference: [...] ## Paris facts: the capital of France in history\\n\\nBefore Paris, the capital of France\\nwas Lyon\\n(under the Romans). Paris first became the capital of France in\\n508 under King Clovis. After centuries with no unique capital of\\nFrance, Paris retrieved its status of capital of France under King\\nPhilippe Auguste, who reigned between 1180 and 1223. You\\ncan see remains of the Philippe August Paris walls in the\\npassageway between the Louvre\\nparking and Louvre Museum',\n",
       "  'score': 0.8877607},\n",
       " {'title': 'France | History, Maps, Flag, Population, Cities, Capital, & Facts',\n",
       "  'url': 'https://www.britannica.com/place/France',\n",
       "  'content': 'The capital and by far the most important city of France is Paris, one of the world’s preeminent cultural and commercial centres. A majestic city known as the ville lumière, or “city of light,” Paris has often been remade, most famously in the mid-19th century under the command of Georges-Eugène, Baron Haussman, who was committed to Napoleon III’s vision of a modern city free of the choleric swamps and congested alleys of old, with broad avenues and a regular plan. Paris is now a sprawling [...] Quick Facts\\n\\nFrance\\n\\nSee article: flag of France\\n\\nAudio File:\\nAnthem of France (see article)\\n\\nHead Of Government:\\n:   Prime minister: François Bayrou\\n\\n(Show more)\\n\\nCapital:\\n:   Paris\\n\\n(Show more)\\n\\nPopulation:\\n:   (2025 est.) 66,607,000\\n\\n(Show more)\\n\\nCurrency Exchange Rate:\\n:   1 USD equals 0.886 euro\\n\\n(Show more)\\n\\nHead Of State:\\n:   President: Emmanuel Macron\\n\\n(Show more)\\n\\nForm Of Government:\\n:   republic with two legislative houses (Parliament; Senate , National Assembly )\\n\\n(Show more) [...] Among France’s other major cities are Lyon, located along an ancient Rhône valley trade route linking the North Sea and the Mediterranean; Marseille, a multiethnic port on the Mediterranean founded as an entrepôt for Greek and Carthaginian traders in the 6th century bce; Nantes, an industrial centre and deepwater harbour along the Atlantic coast; and Bordeaux, located in southwestern France along the Garonne River.\\n\\nBritannica Chatbot logo\\n\\n# Britannica Chatbot',\n",
       "  'score': 0.8729662},\n",
       " {'title': 'Paris - Wikipedia',\n",
       "  'url': 'https://en.wikipedia.org/wiki/Paris',\n",
       "  'content': 'Appearance\\n\\nmove to sidebar hide\\n\\nCoordinates: 48°51′24″N 2°21′8″E / 48.85667°N 2.35222°E / 48.85667; 2.35222_region:FR-75C)\\n\\nImage 4: This is a good article. Click here for more information.\\n\\nImage 5: Page semi-protected\\n\\nFrom Wikipedia, the free encyclopedia\\n\\nCapital and largest city of France\\n\\nThis article is about the capital city of France. For other uses, see Paris (disambiguation) \"Paris (disambiguation)\"). [...] Paris (French pronunciation:( \"Help:IPA/French\")ⓘ) is the capital and largest city of France. With an estimated population of 2,048,472 residents in January 2025( in an area of more than 105 km 2 (41 sq mi),( Paris is the fourth-most populous city in the European Union and the 30th most densely populated city in the world in 2022.( Since the 17th century, Paris has been one of the world\\'s major centres of finance, diplomacy, commerce, culture, fashion, and gastronomy. Because of its leading [...] By the end of the 12th century, Paris had become the political, economic, religious, and cultural capital of France.( The Palais de la Cité, the royal residence, was located at the western end of the Île de la Cité. In 1163, during the reign of Louis VII, Maurice de Sully, bishop of Paris, undertook the construction of the Notre Dame Cathedral at its eastern extremity.',\n",
       "  'score': 0.8668671},\n",
       " {'title': 'Paris, France - Intercultural City - The Council of Europe',\n",
       "  'url': 'https://www.coe.int/en/web/interculturalcities/paris',\n",
       "  'content': 'Paris is the capital and most populous city of France. Situated on the Seine River, in the north of the country, it is in the centre of the Île-de-France region, also known as the région parisienne, \"Paris Region\". The City of Paris has an area of 105 km² and a population of 2,241,346 (2014 estimate). Since the 19th century, the built-up area of Paris has grown far beyond its administrative borders; together with its suburbs, the whole agglomeration has a population of 10,550,350 (Jan. 2012',\n",
       "  'score': 0.8405867}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_tool.invoke(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2718a96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.utilities import PythonREPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5536ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "repl=PythonREPL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60abe4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_code = \"\"\"\n",
    "x=10\n",
    "y=x+10\n",
    "print(y)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7bc146d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'20\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repl.run(my_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ef001c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf50b2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0d7d3fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def python_repl_tool(code: Annotated[str, \"The python code to execute to generate your chart.\"]):\n",
    "    \"\"\"Use this to execute python code and do math. If you want to see the output of a value,\n",
    "    you should print it out with `print(...)`. This is visible to the user.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        result = repl.run(code)\n",
    "    except BaseException as e:\n",
    "        return f\"Failed to execute. Error: {repr(e)}\"\n",
    "    \n",
    "    result_str = f\"Successfully executed:\\n```python\\n{code}\\n```\\nStdout: {result}\"\n",
    "    return result_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbfb4f6",
   "metadata": {},
   "source": [
    "## WE HAVE TWO SUB AGENT\n",
    "RESEARCHER- internet\n",
    "\n",
    "CODER- executing the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "add1094d",
   "metadata": {},
   "outputs": [],
   "source": [
    "members=[\"researcher\",\"coder\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3a2e578d",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = members+[\"FINISH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3aa8e181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['researcher', 'coder', 'FINISH']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d5c0430f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a5b12021",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55724d38",
   "metadata": {},
   "source": [
    "## it is simply going to return the next candidate(next_agent)\n",
    "this next is containig the next candidate name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bffcc905",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Router(TypedDict):\n",
    "    next: Literal['researcher', 'coder', 'FINISH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ef00318c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState,StateGraph,START, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "30f0b15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(MessagesState):\n",
    "    next:str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318d008f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### this is how the state will look like\n",
    "## all messages will be stored in the messages list\n",
    "class State(MessagesState):\n",
    "    next:str\n",
    "state={\"messages\": [\"hi\",\"what is sqt of 42\", \"what is captial of india\"], \"next\": \"research_agent\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "477caf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\"\"\n",
    "You are a supervisor, tasked with managing a conversation between the following workers: {members}. \n",
    "Given the following user request, respond with the worker to act next. \n",
    "Each worker will perform a task and respond with their results and status. \n",
    "When finished, respond with FINISH.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7e54b77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f22dd862",
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervisor_agent(state:State)->Command[Literal['researcher', 'coder', '__end__']]:\n",
    "    \n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt},] + state[\"messages\"]\n",
    "    \n",
    "    llm_with_structure_output=llm.with_structured_output(Router)\n",
    "    \n",
    "    response=llm_with_structure_output.invoke(messages)\n",
    "    \n",
    "    #this is my response {'next': 'researcher'}\n",
    "    \n",
    "    #this is my next worker agent\n",
    "    goto=response[\"next\"]\n",
    "    \n",
    "    print(\"**********BELOW IS MY GOTO***************\")\n",
    "    \n",
    "    print(goto)\n",
    "    \n",
    "    if goto == \"FINISH\":\n",
    "        goto=END\n",
    "    \n",
    "    # class State(MessagesState):\n",
    "    #   next:str\n",
    "    # output of the state: state={\"messages\": [\"hi\"], \"next\": \"researcher\"}\n",
    "    \n",
    "    return Command(goto=goto, update={\"next\":goto})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1e646d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9b0c84c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8e586238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def research_agent(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    \n",
    "    research_agent = create_react_agent(llm, tools=[search_tool], prompt=\"You are a researcher. DO NOT do any math.\")\n",
    "    \n",
    "    result=research_agent.invoke(state)\n",
    "    \n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"researcher\")\n",
    "            ]\n",
    "        },\n",
    "        goto=\"supervisor\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d42f6612",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coder_agent(state:State)->Command[Literal['supervisor']]:\n",
    "    code_agent=create_react_agent(llm,tools=[python_repl_tool], prompt=\"You are a coder. DO NOT do any research.\")\n",
    "    result=code_agent.invoke(state)\n",
    "    \n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"coder\")\n",
    "            ]\n",
    "        },\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875fc284",
   "metadata": {},
   "source": [
    "## this is my orchestration flow with langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "66747276",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph=StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b77d7ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1ccefcf3c50>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.add_node(\"supervisor\", supervisor_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "19e3923f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1ccefcf3c50>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.add_node(\"researcher\", research_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1dffe19c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1ccefcf3c50>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.add_node(\"coder\", coder_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7f8ee7c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1ccefcf3c50>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.add_edge(START, \"supervisor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "22fb2792",
   "metadata": {},
   "outputs": [],
   "source": [
    "app=graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "92b6409b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display,Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "576425c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cada33ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********BELOW IS MY GOTO***************\n",
      "researcher\n",
      "((), {'supervisor': {'next': 'researcher'}})\n",
      "**********BELOW IS MY STATE***************\n",
      "(('researcher:e149b6dc-d7d5-1045-be3f-df0eba1798c9',), {'agent': {'messages': [AIMessage(content='The square root of 42 is approximately 6.4807. In its exact form, it is expressed as √42.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 473, 'prompt_tokens': 179, 'total_tokens': 652, 'completion_time': 1.8178442160000001, 'prompt_time': 0.011223221, 'queue_time': 0.216005178, 'total_time': 1.829067437}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_76307ac09b', 'finish_reason': 'stop', 'logprobs': None}, id='run--12c866cc-7b13-48c1-a42c-1c17f773438a-0', usage_metadata={'input_tokens': 179, 'output_tokens': 473, 'total_tokens': 652})]}})\n",
      "**********BELOW IS MY STATE***************\n",
      "((), {'researcher': {'messages': [HumanMessage(content='The square root of 42 is approximately 6.4807. In its exact form, it is expressed as √42.', additional_kwargs={}, response_metadata={}, name='researcher')]}})\n",
      "**********BELOW IS MY STATE***************\n",
      "**********BELOW IS MY GOTO***************\n",
      "researcher\n",
      "((), {'supervisor': {'next': 'researcher'}})\n",
      "**********BELOW IS MY STATE***************\n",
      "(('researcher:f2468e94-ecd6-fa3f-5a91-92e2ec789728',), {'agent': {'messages': [AIMessage(content='', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 93, 'prompt_tokens': 206, 'total_tokens': 299, 'completion_time': 0.362285213, 'prompt_time': 0.020191494, 'queue_time': 0.202928046, 'total_time': 0.382476707}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_76307ac09b', 'finish_reason': 'stop', 'logprobs': None}, id='run--9d5a1dc9-0215-4887-a000-ce7cfb957cc3-0', usage_metadata={'input_tokens': 206, 'output_tokens': 93, 'total_tokens': 299})]}})\n",
      "**********BELOW IS MY STATE***************\n",
      "((), {'researcher': {'messages': [HumanMessage(content='', additional_kwargs={}, response_metadata={}, name='researcher')]}})\n",
      "**********BELOW IS MY STATE***************\n",
      "**********BELOW IS MY GOTO***************\n",
      "coder\n",
      "((), {'supervisor': {'next': 'coder'}})\n",
      "**********BELOW IS MY STATE***************\n",
      "(('coder:1c0bd5bc-c296-e497-31d3-e7bf48cdcf42',), {'agent': {'messages': [AIMessage(content=\"\\nAlright, so the user is asking for the square root of 42. Hmm, I know that the square root of a number is a value that, when multiplied by itself, gives the original number. So, for 42, I need to find a number that, when squared, equals 42.\\n\\nFirst, I should recall some perfect squares to get an estimate. I know that 6 squared is 36 and 7 squared is 49. Since 42 is between 36 and 49, the square root of 42 must be between 6 and 7. That gives me a rough idea.\\n\\nTo get a more precise value, I can try a few numbers between 6 and 7. Let's see, 6.5 squared is 42.25. Oh, that's pretty close to 42. So, the square root of 42 is just a little less than 6.5. Maybe around 6.48 or something like that.\\n\\nI could use a calculator to find the exact decimal value, but since I don't have one right now, I can approximate it manually. Let's try 6.48 squared: 6.48 * 6.48. Breaking it down, 6 * 6 is 36, 6 * 0.48 is 2.88, 0.48 * 6 is another 2.88, and 0.48 * 0.48 is about 0.2304. Adding those up: 36 + 2.88 + 2.88 + 0.2304 equals approximately 41.99. That's really close to 42, so 6.48 is a good approximation.\\n\\nTherefore, the square root of 42 is approximately 6.4807. In its exact form, it's just √42 since 42 isn't a perfect square and doesn't simplify further.\\n</think>\\n\\nThe square root of 42 is approximately 6.4807. In its exact form, it is expressed as √42.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 422, 'prompt_tokens': 217, 'total_tokens': 639, 'completion_time': 1.534545455, 'prompt_time': 0.021180104, 'queue_time': 0.202537819, 'total_time': 1.5557255589999999}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_76307ac09b', 'finish_reason': 'stop', 'logprobs': None}, id='run--f37fdaf8-3447-43ac-98d8-9b9ed17c62c0-0', usage_metadata={'input_tokens': 217, 'output_tokens': 422, 'total_tokens': 639})]}})\n",
      "**********BELOW IS MY STATE***************\n",
      "((), {'coder': {'messages': [HumanMessage(content=\"\\nAlright, so the user is asking for the square root of 42. Hmm, I know that the square root of a number is a value that, when multiplied by itself, gives the original number. So, for 42, I need to find a number that, when squared, equals 42.\\n\\nFirst, I should recall some perfect squares to get an estimate. I know that 6 squared is 36 and 7 squared is 49. Since 42 is between 36 and 49, the square root of 42 must be between 6 and 7. That gives me a rough idea.\\n\\nTo get a more precise value, I can try a few numbers between 6 and 7. Let's see, 6.5 squared is 42.25. Oh, that's pretty close to 42. So, the square root of 42 is just a little less than 6.5. Maybe around 6.48 or something like that.\\n\\nI could use a calculator to find the exact decimal value, but since I don't have one right now, I can approximate it manually. Let's try 6.48 squared: 6.48 * 6.48. Breaking it down, 6 * 6 is 36, 6 * 0.48 is 2.88, 0.48 * 6 is another 2.88, and 0.48 * 0.48 is about 0.2304. Adding those up: 36 + 2.88 + 2.88 + 0.2304 equals approximately 41.99. That's really close to 42, so 6.48 is a good approximation.\\n\\nTherefore, the square root of 42 is approximately 6.4807. In its exact form, it's just √42 since 42 isn't a perfect square and doesn't simplify further.\\n</think>\\n\\nThe square root of 42 is approximately 6.4807. In its exact form, it is expressed as √42.\", additional_kwargs={}, response_metadata={}, name='coder')]}})\n",
      "**********BELOW IS MY STATE***************\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': ''}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[81], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m app\u001b[38;5;241m.\u001b[39mstream({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms the square root of 42?\u001b[39m\u001b[38;5;124m\"\u001b[39m)]}, subgraphs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(s)\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m**********BELOW IS MY STATE***************\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\MILAN\\anaconda3\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2436\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[0m\n\u001b[0;32m   2434\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mmatch_cached_writes():\n\u001b[0;32m   2435\u001b[0m             loop\u001b[38;5;241m.\u001b[39moutput_writes(task\u001b[38;5;241m.\u001b[39mid, task\u001b[38;5;241m.\u001b[39mwrites, cached\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 2436\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[0;32m   2437\u001b[0m             [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mwrites],\n\u001b[0;32m   2438\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[0;32m   2439\u001b[0m             get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[0;32m   2440\u001b[0m             schedule_task\u001b[38;5;241m=\u001b[39mloop\u001b[38;5;241m.\u001b[39maccept_push,\n\u001b[0;32m   2441\u001b[0m         ):\n\u001b[0;32m   2442\u001b[0m             \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[0;32m   2443\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m output()\n\u001b[0;32m   2444\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\MILAN\\anaconda3\\Lib\\site-packages\\langgraph\\pregel\\runner.py:252\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# panic on failure or timeout\u001b[39;00m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 252\u001b[0m     _panic_or_proceed(\n\u001b[0;32m    253\u001b[0m         futures\u001b[38;5;241m.\u001b[39mdone\u001b[38;5;241m.\u001b[39munion(f \u001b[38;5;28;01mfor\u001b[39;00m f, t \u001b[38;5;129;01min\u001b[39;00m futures\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    254\u001b[0m         panic\u001b[38;5;241m=\u001b[39mreraise,\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    257\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tb \u001b[38;5;241m:=\u001b[39m exc\u001b[38;5;241m.\u001b[39m__traceback__:\n",
      "File \u001b[1;32mc:\\Users\\MILAN\\anaconda3\\Lib\\site-packages\\langgraph\\pregel\\runner.py:509\u001b[0m, in \u001b[0;36m_panic_or_proceed\u001b[1;34m(futs, timeout_exc_cls, panic)\u001b[0m\n\u001b[0;32m    507\u001b[0m                 interrupts\u001b[38;5;241m.\u001b[39mappend(exc)\n\u001b[0;32m    508\u001b[0m             \u001b[38;5;28;01melif\u001b[39;00m fut \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m SKIP_RERAISE_SET:\n\u001b[1;32m--> 509\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m    510\u001b[0m \u001b[38;5;66;03m# raise combined interrupts\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interrupts:\n",
      "File \u001b[1;32mc:\\Users\\MILAN\\anaconda3\\Lib\\site-packages\\langgraph\\pregel\\executor.py:80\u001b[0m, in \u001b[0;36mBackgroundExecutor.done\u001b[1;34m(self, task)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Remove the task from the tasks dict when it's done.\"\"\"\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 80\u001b[0m     task\u001b[38;5;241m.\u001b[39mresult()\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GraphBubbleUp:\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;66;03m# This exception is an interruption signal, not an error\u001b[39;00m\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;66;03m# so we don't want to re-raise it on exit\u001b[39;00m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mpop(task)\n",
      "File \u001b[1;32mc:\\Users\\MILAN\\anaconda3\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\MILAN\\anaconda3\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\MILAN\\anaconda3\\Lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32mc:\\Users\\MILAN\\anaconda3\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m task\u001b[38;5;241m.\u001b[39mproc\u001b[38;5;241m.\u001b[39minvoke(task\u001b[38;5;241m.\u001b[39minput, config)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32mc:\\Users\\MILAN\\anaconda3\\Lib\\site-packages\\langgraph\\utils\\runnable.py:623\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    621\u001b[0m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[0;32m    622\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[1;32m--> 623\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    625\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Users\\MILAN\\anaconda3\\Lib\\site-packages\\langgraph\\utils\\runnable.py:377\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    375\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(ret)\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 377\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[1;32mIn[60], line 7\u001b[0m, in \u001b[0;36msupervisor_agent\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m      3\u001b[0m messages \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: system_prompt},] \u001b[38;5;241m+\u001b[39m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      5\u001b[0m llm_with_structure_output\u001b[38;5;241m=\u001b[39mllm\u001b[38;5;241m.\u001b[39mwith_structured_output(Router)\n\u001b[1;32m----> 7\u001b[0m response\u001b[38;5;241m=\u001b[39mllm_with_structure_output\u001b[38;5;241m.\u001b[39minvoke(messages)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#this is my response {'next': 'researcher'}\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#this is my next worker agent\u001b[39;00m\n\u001b[0;32m     12\u001b[0m goto\u001b[38;5;241m=\u001b[39mresponse[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\MILAN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3045\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3043\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[0;32m   3044\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 3045\u001b[0m         input_ \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, input_, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3046\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3047\u001b[0m         input_ \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, input_, config)\n",
      "File \u001b[1;32mc:\\Users\\MILAN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5431\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   5424\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m   5425\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m   5426\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5429\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   5430\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[1;32m-> 5431\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m   5432\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   5433\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[0;32m   5434\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[0;32m   5435\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\MILAN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:372\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    367\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    368\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    369\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    370\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    371\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m--> 372\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    373\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[0;32m    374\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    375\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    376\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    377\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    378\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    379\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    380\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    381\u001b[0m         )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    382\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32mc:\\Users\\MILAN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:957\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    949\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    950\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    955\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    956\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 957\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\MILAN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:776\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    773\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[0;32m    774\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    775\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 776\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    777\u001b[0m                 m,\n\u001b[0;32m    778\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    779\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    780\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    781\u001b[0m             )\n\u001b[0;32m    782\u001b[0m         )\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\Users\\MILAN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1022\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1020\u001b[0m     result \u001b[38;5;241m=\u001b[39m generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1022\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m   1023\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   1024\u001b[0m     )\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1026\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\MILAN\\anaconda3\\Lib\\site-packages\\langchain_groq\\chat_models.py:498\u001b[0m, in \u001b[0;36mChatGroq._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    493\u001b[0m message_dicts, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[0;32m    494\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    496\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    497\u001b[0m }\n\u001b[1;32m--> 498\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(messages\u001b[38;5;241m=\u001b[39mmessage_dicts, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    499\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[1;32mc:\\Users\\MILAN\\anaconda3\\Lib\\site-packages\\groq\\resources\\chat\\completions.py:361\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, exclude_domains, frequency_penalty, function_call, functions, include_domains, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, n, parallel_tool_calls, presence_penalty, reasoning_format, response_format, search_settings, seed, service_tier, stop, store, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    225\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    226\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m    227\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;124;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;124;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 361\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/openai/v1/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    363\u001b[0m         body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[0;32m    364\u001b[0m             {\n\u001b[0;32m    365\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[0;32m    366\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[0;32m    367\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexclude_domains\u001b[39m\u001b[38;5;124m\"\u001b[39m: exclude_domains,\n\u001b[0;32m    368\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[0;32m    369\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[0;32m    370\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[0;32m    371\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minclude_domains\u001b[39m\u001b[38;5;124m\"\u001b[39m: include_domains,\n\u001b[0;32m    372\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[0;32m    373\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[0;32m    374\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_completion_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_completion_tokens,\n\u001b[0;32m    375\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[0;32m    376\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    377\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[0;32m    378\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n\u001b[0;32m    379\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[0;32m    380\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreasoning_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: reasoning_format,\n\u001b[0;32m    381\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[0;32m    382\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msearch_settings\u001b[39m\u001b[38;5;124m\"\u001b[39m: search_settings,\n\u001b[0;32m    383\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[0;32m    384\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_tier\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_tier,\n\u001b[0;32m    385\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[0;32m    386\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m\"\u001b[39m: store,\n\u001b[0;32m    387\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[0;32m    388\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[0;32m    389\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[0;32m    390\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[0;32m    391\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[0;32m    392\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[0;32m    393\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[0;32m    394\u001b[0m             },\n\u001b[0;32m    395\u001b[0m             completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParams,\n\u001b[0;32m    396\u001b[0m         ),\n\u001b[0;32m    397\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m    398\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m    399\u001b[0m         ),\n\u001b[0;32m    400\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[0;32m    401\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    402\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mStream[ChatCompletionChunk],\n\u001b[0;32m    403\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\MILAN\\anaconda3\\Lib\\site-packages\\groq\\_base_client.py:1225\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1211\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1212\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1213\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1220\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1221\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1222\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1223\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1224\u001b[0m     )\n\u001b[1;32m-> 1225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[1;32mc:\\Users\\MILAN\\anaconda3\\Lib\\site-packages\\groq\\_base_client.py:1034\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1031\u001b[0m             err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1033\u001b[0m         log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1034\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not resolve response (should never happen)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': ''}}",
      "\u001b[0mDuring task with name 'supervisor' and id 'eaf02755-72c5-8445-b483-513edf1a8ed1'"
     ]
    }
   ],
   "source": [
    "for s in app.stream({\"messages\": [(\"user\", \"What's the square root of 42?\")]}, subgraphs=True):\n",
    "    print(s)\n",
    "    print(\"**********BELOW IS MY STATE***************\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
